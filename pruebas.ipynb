{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade -q langchain\n",
    "!pip install google-generativeai langchain-google-genai\n",
    "!pip install chromadb pypdf2 python-dotenv\n",
    "!pip install PyPDF\n",
    "!pip install -U langchain-community\n",
    "!pip install sentence-transformers\n",
    "!pip install langchainhub  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\flori\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Librerías Genéricas  \n",
    "#from google.colab import userdata\n",
    "import os\n",
    "from IPython.display import Markdown\n",
    "\n",
    "# Librerías para la preparación de datos\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import SentenceTransformerEmbeddings\n",
    "\n",
    "# Librerías para el proceso de Retrieval\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "import vertexai \n",
    "from vertexai.generative_models import GenerationConfig, GenerativeModel, Image, Part\n",
    "import vertexai.preview.generative_models as generative_models \n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"C:\\\\Users\\\\flori\\\\OneDrive\\\\Desktop\\\\LDP\\\\ldp-data-genai-producto-b871ebffc681.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define project information\n",
    "PROJECT_ID = \"ldp-data-genai-producto\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Libro(título='Claro', autor=' puedo ayudarte con eso. Como experto en web scraping y análisis de HTML sin procesar', precio=' puedo extraer los datos que necesitas de este HTML.'), Libro(título='Para extraer estos datos', autor=' puedes usar bibliotecas de web scraping en Python como Beautiful Soup y Scrapy', precio=' o herramientas similares en otros lenguajes de programación.  El proceso general sería:'), Libro(título='4. **Almacenar los datos:** Guardar los datos extraídos en un formato estructurado', autor=' como un archivo CSV', precio=' JSON o una base de datos.')]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from langchain import LLMChain\n",
    "from pydantic import BaseModel\n",
    "from selenium import webdriver\n",
    "#from langchain_llms import Gemini\n",
    "\n",
    "# Configuración de Gemini (asegúrate de que esta instancia es correcta)\n",
    "gemini_model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "# Definición de clases\n",
    "class Libro(BaseModel):\n",
    "    \"\"\"Información acerca de un libro\"\"\"\n",
    "    título: str\n",
    "    autor: str\n",
    "    precio: str\n",
    "\n",
    "class LibroScrapper(BaseModel):\n",
    "    \"\"\"Scrapper de libros\"\"\"\n",
    "    url: str\n",
    "    html: str\n",
    "\n",
    "def obtener_html(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Obtener HTML crudo de una página web utilizando Selenium.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        str: HTML crudo de la página web.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "def extraer_info(html: str) -> list[Libro]:\n",
    "    \"\"\"\n",
    "    Extraer información de libros desde el HTML crudo utilizando Gemini.\n",
    "    \n",
    "    Args:\n",
    "        html (str): HTML crudo de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        list[Libro]: Lista de objetos Libro con la información extraída.\n",
    "    \"\"\"\n",
    "    \n",
    "    resultado = gemini_model.generate_content(\n",
    "        f\"\"\"Eres un experto en hacer web scraping y analizar HTML crudo:{html}, si no se proporciona explícitamente no supongas\"\"\",\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=0,\n",
    "            max_output_tokens=8192,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Accede directamente al contenido de `resultado` si es un único objeto\n",
    "    texto_generado = resultado.text  # Asegúrate de que `text` es la propiedad correcta\n",
    "    \n",
    "    libros = []\n",
    "    \n",
    "    # Suponiendo que cada libro está separado por un salto de línea\n",
    "    for libro in texto_generado.split(\"\\n\"):\n",
    "        datos = libro.split(\",\")  # Suponiendo que los datos están separados por comas\n",
    "        if len(datos) == 3:\n",
    "            libros.append(Libro(título=datos[0], autor=datos[1], precio=datos[2]))\n",
    "    \n",
    "    return libros\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.buscalibre.pe\"\n",
    "    html = obtener_html(url)\n",
    "    libros = extraer_info(html)\n",
    "    print(libros)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al decodificar el JSON: ```json\n",
      "[\n",
      "  {\n",
      "    \"título\": \"Alas de Ónix - Saga Empíreo\",\n",
      "    \"autor\": \"Rebecca Yarros\",\n",
      "    \"precio\": \"109.90\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Behave: The Biology of Humans at our Best and Worst (en Inglés)\",\n",
      "    \"autor\": \"Robert M Sapolsky\",\n",
      "    \"precio\": \"78.57\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Globalismo: Ingeniería Social y Control Total en el Siglo xxi\",\n",
      "    \"autor\": \"Agustin Laje\",\n",
      "    \"precio\": \"84.98\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"El Buzón de las Impuras\",\n",
      "    \"autor\": \"Francisca Solar García\",\n",
      "    \"precio\": \"99.60\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Berserk Deluxe Volume 4 (en Inglés)\",\n",
      "    \"autor\": \"Miura, Kentaro ; Miura, Kentaro ; Johnson, Duane\",\n",
      "    \"precio\": \"160.72\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Mitos y leyendas de América\",\n",
      "    \"autor\": \"Carlos Garayar y Jéssica Rodríguez\",\n",
      "    \"precio\": \"50.40\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Estuche Saga Dune 1-6. La Mayor Epopeya de Todos Los Tiempos / Dune Saga Books 1-6. the Greatest Epic Adventure of All Time (Boxed Collection)\",\n",
      "    \"autor\": \"Herbert, Frank\",\n",
      "    \"precio\": \"253.15\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Studio Ghibli: 100 Collectible Postcards: Final Frames From the Feature Films (en Inglés)\",\n",
      "    \"autor\": \"Studio Ghibli\",\n",
      "    \"precio\": \"88.60\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Trono de Cristal\",\n",
      "    \"autor\": \"Sarah J. Maas\",\n",
      "    \"precio\": \"110.70\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Una Corte de Alas y Ruina. Edición Especial\",\n",
      "    \"autor\": \"Sarah J. Maas\",\n",
      "    \"precio\": \"121.04\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Twisted Series 4-Book Boxed set (en Inglés)\",\n",
      "    \"autor\": \"Ana Huang\",\n",
      "    \"precio\": \"161.44\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"La Bendicion del Oficial del Cielo 03. Ed. Especial\",\n",
      "    \"autor\": \"Mo Xiang Tong Xiu\",\n",
      "    \"precio\": \"123.47\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Pride and Prejudice. The Complete Novel: With Nineteen Letters From the Characters'Correspondence (en Inglés)\",\n",
      "    \"autor\": \"Austen, Jane ; Heller, Barbara\",\n",
      "    \"precio\": \"120.10\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Ansiedad 2: Cómo Controlar el Estrés y Mantener el Equilibrio\",\n",
      "    \"autor\": \"Cury, Augusto\",\n",
      "    \"precio\": \"47.53\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"A pesar de ti\",\n",
      "    \"autor\": \"Colleen Hoover\",\n",
      "    \"precio\": \"50.46\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"¿Dónde Está Wally Ahora? / ¿Where Is Waldo Now?\",\n",
      "    \"autor\": \"Handford, Martin\",\n",
      "    \"precio\": \"66.93\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Las Cinco Disfunciones de un Equipo: Un Inteligente Modelo Para Formar un Equipo Cohesionado y Eficaz (Narrativa Empresarial)\",\n",
      "    \"autor\": \"Lencioni, Patrick\",\n",
      "    \"precio\": \"66.81\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"INVITACION AL VIAJE Y OTROS CUENTOS INEDITOS\",\n",
      "    \"autor\": \"Julio Ramón Ribeyro\",\n",
      "    \"precio\": \"57.23\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Ética a Nicómaco\",\n",
      "    \"autor\": \"Aristóteles\",\n",
      "    \"precio\": \"82.91\"\n",
      "  },\n",
      "  {\n",
      "    \"título\": \"Estuche trilogía La casa de los espíritus (contiene La casa de los espíritus | Hija de la fortuna | Retrato en sepia)\",\n",
      "    \"autor\": \"Isabel Allende\",\n",
      "    \"precio\": \"92.01\"\n",
      "  }\n",
      "]\n",
      "```\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "gemini_model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "# Definición de clases\n",
    "class Libro(BaseModel):\n",
    "    \"\"\"Información acerca de un libro\"\"\"\n",
    "    título: str\n",
    "    autor: str\n",
    "    precio: str\n",
    "\n",
    "def obtener_html(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Obtener HTML crudo de una página web utilizando Selenium.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        str: HTML crudo de la página web.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "def extraer_info(html: str) -> list[Libro]:\n",
    "    \"\"\"\n",
    "    Extraer información de libros desde el HTML crudo utilizando Gemini.\n",
    "    \n",
    "    Args:\n",
    "        html (str): HTML crudo de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        list[Libro]: Lista de objetos Libro con la información extraída.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prompt mejorado\n",
    "    prompt = (\n",
    "        \"Por favor, analiza el siguiente HTML y extrae la información de los libros. \"\n",
    "        \"Devuélveme un JSON con una lista de libros, cada uno con los campos 'título', 'autor', y 'precio':\\n\"\n",
    "        f\"{html}\"\n",
    "    )\n",
    "    \n",
    "    resultado = gemini_model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=0,\n",
    "            max_output_tokens=8192,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Supongamos que la respuesta es un JSON string\n",
    "    libros_data = resultado.text.strip()  # Limpiamos espacios en blanco\n",
    "    libros = []\n",
    "    \n",
    "    # Parsear el JSON\n",
    "    try:\n",
    "        libros_json = json.loads(libros_data)\n",
    "        for libro in libros_json:\n",
    "            libros.append(Libro(**libro))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error al decodificar el JSON:\", libros_data)\n",
    "    \n",
    "    return libros\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.buscalibre.pe\"\n",
    "    html = obtener_html(url)\n",
    "    libros = extraer_info(html)\n",
    "    print(libros)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gemini_model = GenerativeModel(\"gemini-1.5-pro-002\")\n",
    "\n",
    "# Definición de clases\n",
    "class Libro(BaseModel):\n",
    "    \"\"\"Información acerca de un libro\"\"\"\n",
    "    título: str\n",
    "    autor: str\n",
    "    precio: str\n",
    "\n",
    "def obtener_html(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Obtener HTML crudo de una página web utilizando Selenium.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        str: HTML crudo de la página web.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "def extraer_info(html: str) -> list[Libro]:\n",
    "    \"\"\"\n",
    "    Extraer información de libros desde el HTML crudo utilizando Gemini.\n",
    "    \n",
    "    Args:\n",
    "        html (str): HTML crudo de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        list[Libro]: Lista de objetos Libro con la información extraída.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prompt mejorado\n",
    "    prompt = (\n",
    "        \"Por favor, analiza el siguiente HTML y extrae la información de los libros. \"\n",
    "        \"Devuélveme un JSON con una lista de libros, cada uno con los campos 'título', 'autor', y 'precio':\\n\"\n",
    "        f\"{html}\"\n",
    "    )\n",
    "    \n",
    "    resultado = gemini_model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=0,\n",
    "            max_output_tokens=8192,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Supongamos que la respuesta es un JSON string\n",
    "    libros_data = resultado.text.strip()  # Limpiamos espacios en blanco\n",
    "    libros = []\n",
    "    \n",
    "    # Parsear el JSON\n",
    "    try:\n",
    "        libros_json = json.loads(libros_data)\n",
    "        for libro in libros_json:\n",
    "            libros.append(Libro(**libro))\n",
    "    except json.JSONDecodeError:\n",
    "        print(\"Error al decodificar el JSON:\", libros_data)\n",
    "    \n",
    "    return libros\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.buscalibre.pe\"\n",
    "    html = obtener_html(url)\n",
    "    libros = extraer_info(html)\n",
    "    print(libros)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "def guardar_cookies(driver, filename):\n",
    "    cookies = driver.get_cookies()\n",
    "    with open(filename, 'w') as file:\n",
    "        json.dump(cookies, file)\n",
    "\n",
    "def cargar_cookies(driver, filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        cookies = json.load(file)\n",
    "        for cookie in cookies:\n",
    "            driver.add_cookie(cookie)\n",
    "\n",
    "# Configurar Selenium\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument(\"--headless\")  # Ejecutar en segundo plano\n",
    "driver = webdriver.Chrome(service=Service(), options=chrome_options)\n",
    "\n",
    "# Iniciar sesión manualmente y guardar cookies\n",
    "driver.get(\"https://www.linkedin.com/home\")\n",
    "input(\"Inicie sesión en LinkedIn y luego presione Enter...\")\n",
    "guardar_cookies(driver, 'cookies.json')\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error al decodificar el JSON: Expecting value: line 1 column 1 (char 0)\n",
      "Respuesta del modelo: ```json\n",
      "[]\n",
      "```\n",
      "\n",
      "El HTML proporcionado no contiene información de libros en un formato que pueda ser fácilmente extraído para crear el JSON deseado.  El HTML muestra la página principal de Buscalibre Perú, con banners, menús de navegación y algunas sugerencias de libros, pero los datos de 'título', 'autor' y 'precio' están embebidos dentro de la estructura HTML de una manera que requiere un análisis más complejo (parsing) con una herramienta específica o una librería de web scraping.\n",
      "\n",
      "Para extraer la información de los libros, necesitarías usar una librería como Beautiful Soup (en Python) o Cheerio (en Node.js) para analizar el HTML y extraer los datos de los elementos relevantes (etiquetas `<h3>` para el título, `<div class=\"autor\">` para el autor y `<p class=\"precio-ahora\">` para el precio).\n",
      "\n",
      "**Ejemplo con Beautiful Soup (Python):**\n",
      "\n",
      "```python\n",
      "import requests\n",
      "from bs4 import BeautifulSoup\n",
      "import json\n",
      "\n",
      "url = 'URL_DEL_HTML' # Reemplaza con la URL real o ruta al archivo HTML\n",
      "\n",
      "response = requests.get(url)\n",
      "soup = BeautifulSoup(response.content, 'html.parser')\n",
      "\n",
      "libros = []\n",
      "for producto in soup.find_all('div', class_='box-producto'):\n",
      "    titulo = producto.find('h3', class_='nombre').text.strip()\n",
      "    autor = producto.find('div', class_='autor').text.strip()\n",
      "    precio = producto.find('p', class_='precio-ahora').text.strip() if producto.find('p', class_='precio-ahora') else None # Manejo de casos donde no hay precio-ahora, por ejemplo, preventas.\n",
      "\n",
      "    if precio: # Solo agrega si el precio existe\n",
      "        precio = float(precio.replace('S/  ', '').replace(',', '.')) # Limpia y convierte a número\n",
      "\n",
      "        libros.append({\n",
      "            'titulo': titulo,\n",
      "            'autor': autor,\n",
      "            'precio': precio\n",
      "        })\n",
      "\n",
      "print(json.dumps(libros, indent=4))\n",
      "```\n",
      "\n",
      "Este código busca todos los divs con la clase `box-producto`, extrae el título, autor y precio, los limpia y los agrega a una lista.  Finalmente, imprime la lista en formato JSON.  Tendrías que adaptar este código si la estructura del HTML cambia.  Además, considera el uso responsable del web scraping, respetando los términos de servicio del sitio web.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Definición de clases\n",
    "class Libro(BaseModel):\n",
    "    \"\"\"Información acerca de un libro\"\"\"\n",
    "    título: str\n",
    "    autor: str\n",
    "    precio: str\n",
    "\n",
    "def obtener_html(url: str) -> str:\n",
    "    \"\"\"\n",
    "    Obtener HTML crudo de una página web utilizando Selenium.\n",
    "    \n",
    "    Args:\n",
    "        url (str): URL de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        str: HTML crudo de la página web.\n",
    "    \"\"\"\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    html = driver.page_source\n",
    "    driver.quit()\n",
    "    return html\n",
    "\n",
    "def extraer_info(html: str) -> list[Libro]:\n",
    "    \"\"\"\n",
    "    Extraer información de libros desde el HTML crudo utilizando Gemini.\n",
    "    \n",
    "    Args:\n",
    "        html (str): HTML crudo de la página web.\n",
    "    \n",
    "    Returns:\n",
    "        list[Libro]: Lista de objetos Libro con la información extraída.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Prompt mejorado\n",
    "    prompt = (\n",
    "        \"Por favor, analiza el siguiente HTML y extrae la información de los libros. \"\n",
    "        \"Devuélveme un JSON con una lista de libros, cada uno con los campos 'título', 'autor', y 'precio':\\n\"\n",
    "        f\"{html}\"\n",
    "    )\n",
    "    \n",
    "    resultado = gemini_model.generate_content(\n",
    "        prompt,\n",
    "        generation_config=GenerationConfig(\n",
    "            temperature=0,\n",
    "            max_output_tokens=8192,\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # Supongamos que la respuesta es un JSON string\n",
    "    libros_data = resultado.text.strip()  # Limpiamos espacios en blanco\n",
    "    libros = []\n",
    "    \n",
    "    # Intentar cargar el JSON\n",
    "    try:\n",
    "        libros_json = json.loads(libros_data)\n",
    "        libros = [Libro(**libro) for libro in libros_json]  # Crear lista de libros\n",
    "    except json.JSONDecodeError as e:\n",
    "        print(\"Error al decodificar el JSON:\", e)\n",
    "        print(\"Respuesta del modelo:\", libros_data)\n",
    "    \n",
    "    return libros\n",
    "\n",
    "def main():\n",
    "    url = \"https://www.buscalibre.pe\"\n",
    "    html = obtener_html(url)\n",
    "    libros = extraer_info(html)\n",
    "    print(libros)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
